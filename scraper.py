from playwright.sync_api import sync_playwright  # å¯¼å…¥ Playwright åŒæ­¥ APIï¼Œç”¨äºæ§åˆ¶æµè§ˆå™¨
from pages.login_page import LoginPage           # å¯¼å…¥ç™»å½•é¡µé¢çš„ Page Object æ¨¡å‹
from pages.inventory_page import InventoryPage   # å¯¼å…¥å•†å“åº“å­˜é¡µé¢çš„ Page Object æ¨¡å‹
from database.db_manager import DBManager        # å¯¼å…¥æ•°æ®åº“ç®¡ç†ç±»ï¼Œç”¨äºåç»­å­˜å‚¨æ•°æ®
from utils.logger import logger                  # å¯¼å…¥æˆ‘ä»¬å°è£…çš„æ—¥å¿—å·¥å…· ğŸš€

def run_scraper():
    """
    çˆ¬è™«ä¸»å…¥å£å‡½æ•°ã€‚
    è´Ÿè´£ç¼–æ’æ•´ä¸ªæŠ“å–æµç¨‹ï¼šå¯åŠ¨æµè§ˆå™¨ -> ç™»å½• -> æŠ“å– -> å­˜åº“ã€‚
    """
    scraped_products = []  # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨æ¥å­˜æ”¾æŠ“å–åˆ°çš„å•†å“æ•°æ®

    # ä½¿ç”¨ context manager (with è¯­å¥) å¯åŠ¨ Playwright
    # è¿™æ ·å¯ä»¥ç¡®ä¿ä»£ç æ‰§è¡Œå®Œæ¯•åï¼Œè‡ªåŠ¨é‡Šæ”¾ Playwright ç›¸å…³çš„èµ„æºï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
    with sync_playwright() as p:
        # 1. å¯åŠ¨æµè§ˆå™¨
        # headless=True è¡¨ç¤ºæ— å¤´æ¨¡å¼ï¼ˆä¸æ˜¾ç¤ºæµè§ˆå™¨ç•Œé¢ï¼‰ï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒæˆ–è‡ªåŠ¨åŒ–è¿è¡Œ
        # å¦‚æœéœ€è¦è°ƒè¯•çœ‹æ•ˆæœï¼Œå¯ä»¥æ”¹ä¸º headless=False
        logger.info("æ­£åœ¨å¯åŠ¨æµè§ˆå™¨ (Chrome Headless)...")
        browser = p.chromium.launch(headless=True)
        
        # 2. åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡ (Context)
        # Context ç›¸å½“äºä¸€ä¸ªç‹¬ç«‹çš„æµè§ˆå™¨ä¼šè¯ï¼ˆç±»ä¼¼éšèº«çª—å£ï¼‰ï¼Œä¸åŒ Context ä¹‹é—´ Cookie ä¸å…±äº«
        context = browser.new_context()
        
        # 3. åœ¨ä¸Šä¸‹æ–‡ä¸­æ‰“å¼€ä¸€ä¸ªæ–°é¡µé¢ (Page)
        # Page ç›¸å½“äºæµè§ˆå™¨ä¸­çš„ä¸€ä¸ªæ ‡ç­¾é¡µ
        page = context.new_page()

        # 4. å®ä¾‹åŒ– POM (Page Object Model) å¯¹è±¡
        # å°† page ä¼ é€’ç»™é¡µé¢å¯¹è±¡ï¼Œè®©å®ƒä»¬èƒ½æ“ä½œè¿™ä¸ªé¡µé¢
        login_page = LoginPage(page)          # ç™»å½•é¡µæ“ä½œå¯¹è±¡
        inventory_page = InventoryPage(page)  # å•†å“åˆ—è¡¨é¡µæ“ä½œå¯¹è±¡

        # 5. æ‰§è¡Œä¸šåŠ¡æµç¨‹
        try:
            # 5.1 æ‰§è¡Œç™»å½•
            logger.info("æ­£åœ¨å°è¯•ç™»å½• SauceDemo...")
            login_page.login("standard_user", "secret_sauce")
            logger.info("ç™»å½•æˆåŠŸï¼")
            
            # 5.2 ç™»å½•æˆåŠŸåï¼ŒæŠ“å–å•†å“æ•°æ®
            logger.info("å¼€å§‹æŠ“å–å•†å“åˆ—è¡¨...")
            scraped_products = inventory_page.get_products()
            logger.info(f"æŠ“å–å®Œæˆï¼Œå…±è·å– {len(scraped_products)} æ¡å•†å“ä¿¡æ¯ã€‚")
            
        except Exception as e:
            # æ•è·æ‰€æœ‰å¼‚å¸¸ï¼Œé˜²æ­¢å› ä¸ºé¡µé¢åŠ è½½å¤±è´¥ç­‰åŸå› å¯¼è‡´ç¨‹åºç›´æ¥å´©æºƒ
            # åœ¨é¢è¯•ä¸­å¯ä»¥å¼ºè°ƒè¿™ç‚¹ï¼šä¿è¯ç¨‹åºçš„å¥å£®æ€§
            logger.error(f"æŠ“å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            
        finally:
            # 6. å…³é—­æµè§ˆå™¨
            # æ”¾åœ¨ finally å—ä¸­ï¼Œç¡®ä¿æ— è®ºæ˜¯å¦å‡ºé”™ï¼Œæµè§ˆå™¨éƒ½èƒ½è¢«æ­£ç¡®å…³é—­
            logger.info("æ­£åœ¨å…³é—­æµè§ˆå™¨...")
            browser.close()

    # 7. æ•°æ®æŒä¹…åŒ– (å­˜å…¥æ•°æ®åº“)
    if scraped_products:
        logger.info("å‡†å¤‡å°†æ•°æ®å­˜å…¥æ•°æ®åº“...")
        db = DBManager()                 # å®ä¾‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        db.save_product(scraped_products) # è°ƒç”¨ä¿å­˜æ–¹æ³•
        db.close()                       # å…³é—­æ•°æ®åº“è¿æ¥
        logger.success("æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼Œæ•°æ®å·²å…¥åº“ï¼")
    else:
        logger.warning("æœªæŠ“å–åˆ°ä»»ä½•å•†å“æ•°æ®ï¼Œè·³è¿‡æ•°æ®åº“ä¿å­˜æ­¥éª¤ã€‚")
    
    return scraped_products

if __name__ == "__main__":
    # å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶æ‰§è¡Œ
    run_scraper()